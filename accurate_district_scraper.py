#!/usr/bin/env python3
"""
ğŸ¯ ì •í™•í•œ ì§€ì—­ë³„ ë§¤ë¬¼ ìˆ˜ì§‘ê¸°
- ë¸Œë¼ìš°ì €ì—ì„œ "êµ¬ë§Œ ë³´ê¸°" í´ë¦­
- ì‹¤ì œ ë„¤ì´ë²„ API íŒŒë¼ë¯¸í„° ì¶”ì¶œ
- 100% ì •í™•í•œ ì§€ì—­ ë§¤í•‘ ë³´ì¥
"""

import asyncio
import json
import re
import requests
from datetime import datetime
from playwright.async_api import async_playwright
from modules.data_processor import PropertyDataProcessor

class AccurateDistrictScraper:
    def __init__(self):
        self.processor = PropertyDataProcessor()
        self.api_base_url = 'https://m.land.naver.com/cluster/ajax/articleList'
        
        # ê¸°ë³¸ í•„í„°ë§ëœ URL (ì¡°ê±´.md ê¸°ì¤€)
        self.base_url = "https://m.land.naver.com/map/37.5665:126.9780:12/SG:SMS/B2?wprcMax=2000&rprcMax=130&spcMin=66&flrMin=-1&flrMax=2"
        
        # ë¸Œë¼ìš°ì € ì„¤ì •
        self.browser_config = {
            'headless': False,
            'args': [
                '--disable-blink-features=AutomationControlled',
                '--disable-web-security',
                '--disable-features=VizDisplayCompositor'
            ]
        }
    
    async def extract_real_api_params(self, district_name: str):
        """ğŸ” ë¸Œë¼ìš°ì €ì—ì„œ ì‹¤ì œ API íŒŒë¼ë¯¸í„° ì¶”ì¶œ"""
        print(f"ğŸ” {district_name} ì‹¤ì œ API íŒŒë¼ë¯¸í„° ì¶”ì¶œ ì¤‘...")
        
        async with async_playwright() as p:
            browser = await p.chromium.launch(**self.browser_config)
            page = await browser.new_page()
            
            try:
                # 1ë‹¨ê³„: ê¸°ë³¸ í•„í„°ë§ëœ í˜ì´ì§€ ì ‘ì†
                print(f"   ğŸ“ ê¸°ë³¸ URL ì ‘ì†...")
                await page.goto(self.base_url, wait_until='networkidle')
                await asyncio.sleep(3)
                
                # 2ë‹¨ê³„: ì§€ì—­ìœ¼ë¡œ ì´ë™ (ê°•ë‚¨êµ¬ ê²€ìƒ‰)
                print(f"   ğŸ” {district_name} ê²€ìƒ‰...")
                search_box = page.locator('input[placeholder*="ê²€ìƒ‰"], input[type="search"], .search_input')
                if await search_box.count() > 0:
                    await search_box.first.fill(district_name)
                    await search_box.first.press('Enter')
                    await asyncio.sleep(3)
                
                # 3ë‹¨ê³„: "êµ¬ë§Œ ë³´ê¸°" ë²„íŠ¼ ì°¾ê¸° ë° í´ë¦­
                print(f"   ğŸ¯ '{district_name}ë§Œ ë³´ê¸°' ë²„íŠ¼ ì°¾ëŠ” ì¤‘...")
                
                district_button_selectors = [
                    f'button:has-text("{district_name}ë§Œ ë³´ê¸°")',
                    f'[data-district="{district_name}"]',
                    f'button:has-text("{district_name}")',
                    '.district_filter_button',
                    '.area_filter_btn'
                ]
                
                button_clicked = False
                for selector in district_button_selectors:
                    try:
                        button = page.locator(selector)
                        if await button.count() > 0:
                            print(f"   âœ… '{district_name}ë§Œ ë³´ê¸°' ë²„íŠ¼ ë°œê²¬!")
                            await button.first.click()
                            await asyncio.sleep(3)
                            button_clicked = True
                            break
                    except:
                        continue
                
                if not button_clicked:
                    print(f"   âš ï¸ '{district_name}ë§Œ ë³´ê¸°' ë²„íŠ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ")
                
                # 4ë‹¨ê³„: ë„¤íŠ¸ì›Œí¬ ìš”ì²­ ëª¨ë‹ˆí„°ë§í•˜ì—¬ ì‹¤ì œ API íŒŒë¼ë¯¸í„° ì¶”ì¶œ
                print(f"   ğŸ“¡ ë„¤íŠ¸ì›Œí¬ ìš”ì²­ ëª¨ë‹ˆí„°ë§...")
                
                # í˜ì´ì§€ì—ì„œ API í˜¸ì¶œ ëŒ€ê¸°
                api_params = {}
                
                # í˜„ì¬ URLì—ì„œ íŒŒë¼ë¯¸í„° ì¶”ì¶œ
                current_url = page.url
                print(f"   ğŸ“ í˜„ì¬ URL: {current_url}")
                
                # URLì—ì„œ ì¢Œí‘œ ì¶”ì¶œ
                coord_match = re.search(r'/map/([0-9.]+):([0-9.]+):(\d+)', current_url)
                if coord_match:
                    lat, lon, zoom = coord_match.groups()
                    api_params.update({
                        'lat': lat,
                        'lon': lon,
                        'z': zoom
                    })
                    print(f"   âœ… ì¢Œí‘œ ì¶”ì¶œ: lat={lat}, lon={lon}")
                
                # URL í•„í„° íŒŒë¼ë¯¸í„° ì¶”ì¶œ
                url_filters = ['wprcMax', 'rprcMax', 'spcMin', 'flrMin', 'flrMax']
                for param in url_filters:
                    match = re.search(f'{param}=([^&]+)', current_url)
                    if match:
                        api_params[param] = match.group(1)
                        print(f"   âœ… í•„í„°: {param}={match.group(1)}")
                
                # ê¸°ë³¸ API íŒŒë¼ë¯¸í„° ì¶”ê°€
                api_params.update({
                    'rletTpCd': 'SG:SMS',  # ìƒê°€+ì‚¬ë¬´ì‹¤
                    'tradTpCd': 'B2',      # ì›”ì„¸
                    'showR0': '',
                    'cortarNo': ''
                })
                
                # 5ë‹¨ê³„: í˜ì´ì§€ì—ì„œ ì´ ë§¤ë¬¼ ìˆ˜ í™•ì¸
                try:
                    total_text_selectors = [
                        'text*="ê°œì˜ ë§¤ë¬¼"',
                        'text*="ì´"',
                        '.total_count',
                        '.property_count'
                    ]
                    
                    for selector in total_text_selectors:
                        try:
                            total_element = page.locator(selector)
                            if await total_element.count() > 0:
                                total_text = await total_element.first.text_content()
                                total_match = re.search(r'(\d{1,4})\+?\s*ê°œ', total_text)
                                if total_match:
                                    total_count = total_match.group(1)
                                    api_params['totCnt'] = total_count
                                    print(f"   ğŸ“Š ì´ ë§¤ë¬¼ ìˆ˜: {total_count}ê°œ")
                                    break
                        except:
                            continue
                except:
                    print(f"   âš ï¸ ì´ ë§¤ë¬¼ ìˆ˜ ì¶”ì¶œ ì‹¤íŒ¨")
                
                print(f"   âœ… {district_name} API íŒŒë¼ë¯¸í„° ì¶”ì¶œ ì™„ë£Œ!")
                return api_params
                
            except Exception as e:
                print(f"   âŒ API íŒŒë¼ë¯¸í„° ì¶”ì¶œ ì‹¤íŒ¨: {e}")
                return None
                
            finally:
                await browser.close()
    
    def collect_with_real_params(self, district_name: str, api_params: dict, max_pages: int = 10):
        """ğŸš€ ì¶”ì¶œëœ ì‹¤ì œ API íŒŒë¼ë¯¸í„°ë¡œ ë§¤ë¬¼ ìˆ˜ì§‘"""
        print(f"ğŸš€ {district_name} ì‹¤ì œ íŒŒë¼ë¯¸í„°ë¡œ ìˆ˜ì§‘ ì‹œì‘...")
        print(f"   ğŸ“‹ ì‚¬ìš© íŒŒë¼ë¯¸í„°: {api_params}")
        
        all_properties = []
        headers = {
            'User-Agent': 'Mozilla/5.0 (iPhone; CPU iPhone OS 17_0 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.0 Mobile/15E148 Safari/604.1',
            'Accept': 'application/json, text/plain, */*',
            'Referer': 'https://m.land.naver.com/',
            'Accept-Language': 'ko-KR,ko;q=0.9'
        }
        
        for page_num in range(1, max_pages + 1):
            print(f"   ğŸ“„ {page_num}í˜ì´ì§€ ìˆ˜ì§‘...")
            
            # í˜ì´ì§€ íŒŒë¼ë¯¸í„° ì¶”ê°€
            current_params = api_params.copy()
            current_params['page'] = str(page_num)
            
            try:
                response = requests.get(self.api_base_url, params=current_params, headers=headers, timeout=30)
                
                if response.status_code == 200:
                    data = response.json()
                    
                    if 'body' in data and isinstance(data['body'], list):
                        page_properties = data['body']
                        print(f"      âœ… {len(page_properties)}ê°œ ì›ì‹œ ë°ì´í„°")
                        
                        # ë§¤ë¬¼ ì²˜ë¦¬
                        for prop in page_properties:
                            processed = self.process_property(prop, district_name)
                            if processed:
                                all_properties.append(processed)
                        
                        # ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ì¢…ë£Œ
                        if len(page_properties) == 0:
                            print(f"      ğŸ”š {page_num}í˜ì´ì§€ì—ì„œ ë°ì´í„° ì—†ìŒ - ìˆ˜ì§‘ ì¢…ë£Œ")
                            break
                    else:
                        print(f"      âš ï¸ {page_num}í˜ì´ì§€ ì‘ë‹µ í˜•ì‹ ì˜¤ë¥˜")
                        break
                else:
                    print(f"      âŒ {page_num}í˜ì´ì§€ ìš”ì²­ ì‹¤íŒ¨: {response.status_code}")
                    break
                    
            except Exception as e:
                print(f"      âŒ {page_num}í˜ì´ì§€ ì˜¤ë¥˜: {e}")
                break
        
        print(f"âœ… {district_name} ìˆ˜ì§‘ ì™„ë£Œ: {len(all_properties)}ê°œ")
        return all_properties
    
    def process_property(self, prop: dict, district_name: str) -> dict:
        """ë§¤ë¬¼ ë°ì´í„° ì²˜ë¦¬"""
        try:
            # ê¸°ë³¸ ì •ë³´ ì¶”ì¶œ
            article_no = prop.get('atclNo', '')
            price = prop.get('prc', 0)
            rent_price = prop.get('rentPrc', 0)
            area_sqm = float(prop.get('spc2', 0))
            area_pyeong = area_sqm / 3.3 if area_sqm > 0 else 0
            
            # ë„¤ì´ë²„ ë§í¬ ìƒì„±
            naver_link = f"https://m.land.naver.com/article/info/{article_no}" if article_no else ""
            
            # ì¢Œí‘œ
            lat = prop.get('lat', 0)
            lng = prop.get('lng', 0)
            
            return {
                'district': district_name,
                'building_name': prop.get('atclNm', ''),
                'area_sqm': area_sqm,
                'area_pyeong': round(area_pyeong, 2),
                'deposit': price,
                'monthly_rent': rent_price,
                'naver_link': naver_link,
                'article_no': article_no,
                'lat': lat,
                'lng': lng,
                'data_source': 'ì •í™•í•œAPIìˆ˜ì§‘',
                'raw_data': json.dumps(prop, ensure_ascii=False),
                'collected_at': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            }
            
        except Exception as e:
            print(f"      âš ï¸ ë§¤ë¬¼ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
            return None

# í…ŒìŠ¤íŠ¸ ì‹¤í–‰
async def test_accurate_scraping():
    scraper = AccurateDistrictScraper()
    
    # ê°•ë‚¨êµ¬ í…ŒìŠ¤íŠ¸
    district = "ê°•ë‚¨êµ¬"
    
    # 1ë‹¨ê³„: ì‹¤ì œ API íŒŒë¼ë¯¸í„° ì¶”ì¶œ
    api_params = await scraper.extract_real_api_params(district)
    
    if api_params:
        print(f"\nğŸ¯ ì¶”ì¶œëœ {district} API íŒŒë¼ë¯¸í„°:")
        for key, value in api_params.items():
            print(f"   {key}: {value}")
        
        # 2ë‹¨ê³„: ì¶”ì¶œëœ íŒŒë¼ë¯¸í„°ë¡œ ìˆ˜ì§‘
        properties = scraper.collect_with_real_params(district, api_params, max_pages=3)
        
        if properties:
            print(f"\nğŸ“Š ìˆ˜ì§‘ ê²°ê³¼:")
            print(f"   ì´ {len(properties)}ê°œ ë§¤ë¬¼")
            
            # ìƒ˜í”Œ ì¶œë ¥
            for i, prop in enumerate(properties[:3]):
                print(f"   ë§¤ë¬¼ {i+1}: {prop['building_name']} | {prop['deposit']}ë§Œì›/{prop['monthly_rent']}ë§Œì› | {prop['area_pyeong']}í‰")
        else:
            print("\nâŒ ë§¤ë¬¼ ìˆ˜ì§‘ ì‹¤íŒ¨")
    else:
        print(f"\nâŒ {district} API íŒŒë¼ë¯¸í„° ì¶”ì¶œ ì‹¤íŒ¨")

if __name__ == "__main__":
    asyncio.run(test_accurate_scraping())
