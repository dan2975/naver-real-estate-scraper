import pandas as pd
import sqlite3
import os
from datetime import datetime

class PropertyDataProcessor:
    """ë¶€ë™ì‚° ë°ì´í„° ì²˜ë¦¬ ë° í•„í„°ë§ í´ë˜ìŠ¤"""
    
    def __init__(self):
        # ê¸°ë³¸ ì„¤ì •
        self.db_path = 'data/properties.db'
        self.filter_conditions = {
            'max_deposit': 2000,      # ë³´ì¦ê¸ˆ 2000ë§Œì› ì´í•˜
            'max_monthly_rent': 130,  # ì›”ì„¸ 130ë§Œì› ì´í•˜  
            'max_total_monthly': 150, # ì´ ì›”ë¹„ìš© 150ë§Œì› ì´í•˜
            'min_area_pyeong': 20,    # 20í‰ ì´ìƒ
            'min_floor': -1,          # ì§€í•˜1ì¸µ ì´ìƒ
            'max_floor': 2,           # 2ì¸µ ì´í•˜
            'max_management_fee': 30  # ê´€ë¦¬ë¹„ 30ë§Œì› ì´í•˜
        }
        
        # ğŸ¯ CSV â†” DB ì»¬ëŸ¼ ë§¤í•‘
        self.csv_to_db_mapping = {
            'district': 'district',
            'property_type': 'data_source',  # property_typeì„ data_sourceë¡œ ë§¤í•‘
            'deposit': 'deposit',
            'monthly_rent': 'monthly_rent',
            'area_sqm': 'area_sqm',
            'area_pyeong': 'area_pyeong',
            'floor': 'floor',
            'floor_info': None,  # DBì— ì €ì¥í•˜ì§€ ì•ŠìŒ
            'building_name': 'building_name',
            'property_name': None,  # DBì— ì €ì¥í•˜ì§€ ì•ŠìŒ
            'full_address': 'full_address',
            'road_address': None,  # DBì— ì €ì¥í•˜ì§€ ì•ŠìŒ
            'jibun_address': None,  # DBì— ì €ì¥í•˜ì§€ ì•ŠìŒ
            'naver_link': 'naver_link',
            'article_no': None,  # raw_textì— í¬í•¨
            'raw_data': 'raw_text'
        }
        
        self.ensure_data_directory()
        
    def ensure_data_directory(self):
        """ë°ì´í„° ë””ë ‰í† ë¦¬ ìƒì„±"""
        os.makedirs(os.path.dirname(self.db_path), exist_ok=True)
        
    def create_tables(self):
        """ë°ì´í„°ë² ì´ìŠ¤ í…Œì´ë¸” ìƒì„±"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        # ë§¤ë¬¼ ì •ë³´ í…Œì´ë¸”
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS properties (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                region TEXT,
                district TEXT,
                building_name TEXT,
                full_address TEXT,
                area_sqm REAL,
                area_pyeong REAL,
                floor INTEGER,
                total_floors INTEGER,
                floor_display TEXT,
                deposit INTEGER,
                monthly_rent INTEGER,
                management_fee INTEGER,
                total_monthly_cost REAL,
                ceiling_height REAL,
                parking_available BOOLEAN,
                near_station BOOLEAN,
                build_year INTEGER,
                naver_link TEXT,
                data_source TEXT,
                score INTEGER DEFAULT 0,
                        labels TEXT,
                        collected_at TIMESTAMP,
                        raw_text TEXT,
                        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        ''')
        
        conn.commit()
        conn.close()
    
    def csv_to_db_dataframe(self, csv_df: pd.DataFrame) -> pd.DataFrame:
        """ğŸ”„ CSV ë°ì´í„°ë¥¼ DB í˜•ì‹ìœ¼ë¡œ ë³€í™˜ (ìŠ¤ë§ˆíŠ¸ íŒŒì‹± í¬í•¨)"""
        import ast
        import re
        
        db_df = pd.DataFrame()
        
        # ë§¤í•‘ëœ ì»¬ëŸ¼ë“¤ ë³€í™˜
        for csv_col, db_col in self.csv_to_db_mapping.items():
            if db_col and csv_col in csv_df.columns:
                db_df[db_col] = csv_df[csv_col]
        
        # ğŸ¯ ìŠ¤ë§ˆíŠ¸ ë°ì´í„° íŒŒì‹± ë° ë³´ì™„
        current_time_str = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        
        # ğŸ¢ ì¸µìˆ˜ ì •ë³´ ê°œì„  (floor_infoì—ì„œ ì´ ì¸µìˆ˜ ì¶”ì¶œ)
        if 'floor_info' in csv_df.columns:
            def parse_floor_info(floor_info):
                if pd.isna(floor_info) or floor_info == '':
                    return None, None, None
                
                floor_str = str(floor_info)
                
                # "ì „ì²´ì¸µ/15" íŒ¨í„´
                if 'ì „ì²´ì¸µ' in floor_str:
                    if '/' in floor_str:
                        total = floor_str.split('/')[1]
                        try:
                            total_floors = int(total)
                            return 0, total_floors, f"ì „ì²´ì¸µ ({total_floors}ì¸µ ê±´ë¬¼)"
                        except:
                            return 0, None, "ì „ì²´ì¸µ"
                    else:
                        return 0, None, "ì „ì²´ì¸µ"
                
                # "1/4", "B1/5" ë“± ì¼ë°˜ íŒ¨í„´
                if '/' in floor_str:
                    parts = floor_str.split('/')
                    if len(parts) == 2:
                        current_part = parts[0].strip()
                        total_part = parts[1].strip()
                        
                        try:
                            # í˜„ì¬ ì¸µ íŒŒì‹±
                            if current_part.startswith('B'):
                                current_floor = -int(current_part[1:])  # B1 â†’ -1
                                current_display = f"ì§€í•˜{current_part[1:]}ì¸µ"
                            else:
                                current_floor = int(current_part)
                                current_display = f"{current_part}ì¸µ"
                            
                            # ì´ ì¸µìˆ˜ íŒŒì‹±
                            total_floors = int(total_part)
                            
                            # í‘œì‹œìš© ë¬¸ìì—´
                            display = f"{current_display} ({total_floors}ì¸µ ê±´ë¬¼)"
                            
                            return current_floor, total_floors, display
                        except:
                            pass
                
                # íŒŒì‹± ì‹¤íŒ¨ì‹œ ê¸°ë³¸ê°’
                return None, None, floor_str
            
            # ê° í–‰ì— ëŒ€í•´ ì¸µìˆ˜ ì •ë³´ íŒŒì‹±
            floor_data = csv_df['floor_info'].apply(parse_floor_info)
            
            # ê²°ê³¼ë¥¼ ê°œë³„ ì»¬ëŸ¼ìœ¼ë¡œ ë¶„ë¦¬
            db_df['floor'] = [item[0] for item in floor_data]
            db_df['total_floors'] = [item[1] for item in floor_data]
            db_df['floor_display'] = [item[2] for item in floor_data]
        
        # building_name ë³´ì™„ (property_name ìš°ì„  ì‚¬ìš©, NaN ì²˜ë¦¬)
        if 'property_name' in csv_df.columns:
            # NaNì„ ë¹ˆ ë¬¸ìì—´ë¡œ ë³€í™˜í•˜ì—¬ ì²˜ë¦¬
            property_names = csv_df['property_name'].fillna('')
            building_names = csv_df.get('building_name', pd.Series([''] * len(csv_df))).fillna('')
            db_df['building_name'] = property_names.where(property_names != '', building_names)
        
        # full_address ë³´ì™„ (road_address -> jibun_address ìˆœì„œ)
        if 'road_address' in csv_df.columns and 'jibun_address' in csv_df.columns:
            db_df['full_address'] = csv_df['road_address'].fillna(csv_df['jibun_address']).fillna('')
        elif 'road_address' in csv_df.columns:
            db_df['full_address'] = csv_df['road_address'].fillna('')
        elif 'jibun_address' in csv_df.columns:
            db_df['full_address'] = csv_df['jibun_address'].fillna('')
        
        # raw_dataì—ì„œ ì¶”ê°€ ì •ë³´ íŒŒì‹±
        if 'raw_data' in csv_df.columns:
            def parse_raw_data(row):
                try:
                    if pd.isna(row['raw_data']) or row['raw_data'] == '':
                        return row
                    
                    # Python dict íŒŒì‹± (JSONì´ ì•„ë‹˜)
                    if isinstance(row['raw_data'], str):
                        import ast
                        raw_data = ast.literal_eval(row['raw_data'])
                    else:
                        raw_data = row['raw_data']
                    
                    # ê´€ë¦¬ë¹„ íŒŒì‹± (minMviFee, maxMviFee)
                    min_fee = raw_data.get('minMviFee', 0)
                    max_fee = raw_data.get('maxMviFee', 0)
                    if max_fee > 0:
                        row['management_fee'] = max_fee
                    elif min_fee > 0:
                        row['management_fee'] = min_fee
                    
                    # ê±´ë¬¼ëª… ë³´ì™„ (bildNm)
                    if pd.isna(row.get('building_name', '')) or row.get('building_name', '') == '':
                        row['building_name'] = raw_data.get('bildNm', raw_data.get('atclNm', ''))
                    
                    # ì£¼ì°¨ ê°€ëŠ¥ ì—¬ë¶€ (tagListì—ì„œ 'ì£¼ì°¨ê°€ëŠ¥' ì°¾ê¸°)
                    tag_list = raw_data.get('tagList', [])
                    if isinstance(tag_list, list):
                        row['parking_available'] = 'ì£¼ì°¨ê°€ëŠ¥' in tag_list or 'ì£¼ì°¨' in ' '.join(tag_list)
                    
                    # ì—­ì„¸ê¶Œ ì—¬ë¶€ (atclFetrDescì—ì„œ 'ì—­', 'ì§€í•˜ì² ', 'ë¶„ê±°ë¦¬' ì°¾ê¸°)
                    desc = raw_data.get('atclFetrDesc', '')
                    if isinstance(desc, str):
                        station_keywords = ['ì—­', 'ì§€í•˜ì² ', 'ë¶„ê±°ë¦¬', 'ì—­ì„¸ê¶Œ', 'í˜¸ì„ ']
                        row['near_station'] = any(keyword in desc for keyword in station_keywords)
                    
                    # ğŸ¯ ì¢Œí‘œ ì •ë³´ ì €ì¥
                    lat = raw_data.get('lat', 0)
                    lng = raw_data.get('lng', 0)
                    if lat and lng:
                        row['lat'] = float(lat)
                        row['lng'] = float(lng)
                    
                    # ìƒì„¸ì£¼ì†Œ ë³´ì™„ (dtlAddr ìš°ì„ , ì—†ìœ¼ë©´ ì§€ì—­êµ¬ + ì¢Œí‘œ ì •ë³´)
                    if pd.isna(row.get('full_address', '')) or row.get('full_address', '') == '':
                        dtl_addr = raw_data.get('dtlAddr', '')
                        if dtl_addr:
                            row['full_address'] = dtl_addr
                        else:
                            # ì§€ì—­êµ¬ + ì¢Œí‘œë¡œ ëŒ€ëµì  ì£¼ì†Œ ìƒì„±
                            district = row.get('district', '')
                            if district and lat and lng:
                                row['full_address'] = f"ì„œìš¸íŠ¹ë³„ì‹œ {district} (ìœ„ë„: {lat}, ê²½ë„: {lng})"
                    
                    return row
                except Exception as e:
                    print(f"âš ï¸ raw_data íŒŒì‹± ì˜¤ë¥˜: {e}")
                    return row
            
            # ê° í–‰ì— ëŒ€í•´ raw_data íŒŒì‹± ì ìš©
            for idx in range(len(csv_df)):
                row_dict = csv_df.iloc[idx].to_dict()
                parsed_row = parse_raw_data(row_dict)
                
                # íŒŒì‹±ëœ ê°’ë“¤ì„ db_dfì— ì ìš©
                if 'management_fee' in parsed_row:
                    if idx >= len(db_df):
                        continue
                    if 'management_fee' not in db_df.columns:
                        db_df['management_fee'] = 0
                    db_df.at[idx, 'management_fee'] = parsed_row['management_fee']
                
                if 'building_name' in parsed_row:
                    if 'building_name' not in db_df.columns:
                        db_df['building_name'] = ''
                    db_df.at[idx, 'building_name'] = parsed_row['building_name']
                
                if 'parking_available' in parsed_row:
                    if 'parking_available' not in db_df.columns:
                        db_df['parking_available'] = False
                    db_df.at[idx, 'parking_available'] = parsed_row['parking_available']
                
                if 'near_station' in parsed_row:
                    if 'near_station' not in db_df.columns:
                        db_df['near_station'] = False
                    db_df.at[idx, 'near_station'] = parsed_row['near_station']
                
                if 'full_address' in parsed_row:
                    if 'full_address' not in db_df.columns:
                        db_df['full_address'] = ''
                    db_df.at[idx, 'full_address'] = parsed_row['full_address']
                
                # ğŸ¯ ì¢Œí‘œ ë°ì´í„° ì ìš©
                if 'lat' in parsed_row:
                    if 'lat' not in db_df.columns:
                        db_df['lat'] = 0.0
                    db_df.at[idx, 'lat'] = parsed_row['lat']
                
                if 'lng' in parsed_row:
                    if 'lng' not in db_df.columns:
                        db_df['lng'] = 0.0
                    db_df.at[idx, 'lng'] = parsed_row['lng']
        
        # ê¸°ë³¸ê°’ ì„¤ì • (íŒŒì‹±ë˜ì§€ ì•Šì€ ì»¬ëŸ¼ë“¤)
        db_df['region'] = 'ì„œìš¸íŠ¹ë³„ì‹œ'
        
        if 'management_fee' not in db_df.columns:
            db_df['management_fee'] = 0
        
        if 'total_monthly_cost' not in db_df.columns:
            db_df['total_monthly_cost'] = db_df.get('monthly_rent', 0) + db_df.get('management_fee', 0)
        else:
            db_df['total_monthly_cost'] = db_df.get('monthly_rent', 0) + db_df.get('management_fee', 0)
        
        if 'ceiling_height' not in db_df.columns:
            db_df['ceiling_height'] = 0.0
        
        if 'parking_available' not in db_df.columns:
            db_df['parking_available'] = False
        
        if 'near_station' not in db_df.columns:
            db_df['near_station'] = False
        
        if 'build_year' not in db_df.columns:
            db_df['build_year'] = 0
        
        if 'building_name' not in db_df.columns:
            db_df['building_name'] = ''
        
        if 'full_address' not in db_df.columns:
            db_df['full_address'] = ''
        
        # ì¸µìˆ˜ ê´€ë ¨ ê¸°ë³¸ê°’
        if 'floor' not in db_df.columns:
            db_df['floor'] = 0
        if 'total_floors' not in db_df.columns:
            db_df['total_floors'] = 0
        if 'floor_display' not in db_df.columns:
            db_df['floor_display'] = ''
        
        db_df['score'] = 0
        db_df['labels'] = ''
        db_df['collected_at'] = current_time_str
        db_df['created_at'] = current_time_str
        
        return db_df
    
    def import_csv_to_db(self, csv_file_path: str, overwrite: bool = True) -> int:
        """ğŸ“¥ CSV íŒŒì¼ì„ DBë¡œ ê°€ì ¸ì˜¤ê¸° (ë®ì–´ì“°ê¸° ì˜µì…˜)"""
        try:
            # CSV íŒŒì¼ ì½ê¸°
            csv_df = pd.read_csv(csv_file_path)
            print(f"ğŸ“ CSV íŒŒì¼ ë¡œë“œ: {len(csv_df)}ê°œ ë ˆì½”ë“œ")
            
            # DB í˜•ì‹ìœ¼ë¡œ ë³€í™˜
            db_df = self.csv_to_db_dataframe(csv_df)
            print(f"ğŸ”„ DB í˜•ì‹ ë³€í™˜ ì™„ë£Œ: {len(db_df)}ê°œ ë ˆì½”ë“œ")
            
            # ë®ì–´ì“°ê¸° ì˜µì…˜ ì²˜ë¦¬
            if overwrite:
                print("ğŸ—‘ï¸ ê¸°ì¡´ DB ë°ì´í„° ì‚­ì œ ì¤‘...")
                self.clear_all_properties()
            
            # DBì— ì €ì¥
            saved_count = 0
            conn = sqlite3.connect(self.db_path)
            
            for _, row in db_df.iterrows():
                try:
                    # INSERT ì¿¼ë¦¬ ì‹¤í–‰
                    columns = ', '.join(row.index)
                    placeholders = ', '.join(['?' for _ in row.index])
                    query = f"INSERT INTO properties ({columns}) VALUES ({placeholders})"
                    
                    conn.execute(query, tuple(row.values))
                    saved_count += 1
                    
                except Exception as e:
                    print(f"âš ï¸ ë ˆì½”ë“œ ì €ì¥ ì˜¤ë¥˜: {e}")
                    continue
            
            conn.commit()
            conn.close()
            
            print(f"âœ… CSV â†’ DB ê°€ì ¸ì˜¤ê¸° ì™„ë£Œ: {saved_count}/{len(db_df)}ê°œ ì €ì¥ë¨")
            return saved_count
            
        except Exception as e:
            print(f"âŒ CSV â†’ DB ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: {e}")
            return 0
    
    def clear_all_properties(self):
        """ğŸ—‘ï¸ ëª¨ë“  ë§¤ë¬¼ ë°ì´í„° ì‚­ì œ"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        cursor.execute("DELETE FROM properties")
        deleted_count = cursor.rowcount
        conn.commit()
        conn.close()
        print(f"ğŸ—‘ï¸ {deleted_count}ê°œ ê¸°ì¡´ ë ˆì½”ë“œ ì‚­ì œë¨")
        return deleted_count
    
    def get_all_properties_from_db(self) -> pd.DataFrame:
        """ğŸ“Š DBì—ì„œ ëª¨ë“  ë§¤ë¬¼ ë°ì´í„° ì¡°íšŒ"""
        try:
            conn = sqlite3.connect(self.db_path)
            query = "SELECT * FROM properties ORDER BY created_at DESC"
            df = pd.read_sql_query(query, conn)
            conn.close()
            
            print(f"ğŸ“Š DBì—ì„œ {len(df)}ê°œ ë§¤ë¬¼ ë¡œë“œë¨")
            return df
            
        except Exception as e:
            print(f"âŒ DB ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return pd.DataFrame()
    
    def get_properties_count(self) -> int:
        """ğŸ“Š DB ë§¤ë¬¼ ê°œìˆ˜ ì¡°íšŒ"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            cursor.execute("SELECT COUNT(*) FROM properties")
            count = cursor.fetchone()[0]
            conn.close()
            return count
        except:
            return 0
    
    def is_property_exists(self, naver_link: str) -> bool:
        """ğŸ” ë§¤ë¬¼ì´ DBì— ì´ë¯¸ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸ (naver_link ê¸°ì¤€)"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            cursor.execute("SELECT COUNT(*) FROM properties WHERE naver_link = ?", (naver_link,))
            count = cursor.fetchone()[0]
            conn.close()
            return count > 0
        except:
            return False
    
    def upsert_property(self, property_data: dict) -> str:
        """ğŸ”„ ë§¤ë¬¼ UPSERT (ì¤‘ë³µ ì‹œ ì—…ë°ì´íŠ¸, ì‹ ê·œ ì‹œ ì‚½ì…)"""
        try:
            naver_link = property_data.get('naver_link', '')
            if not naver_link:
                return "âŒ naver_linkê°€ ì—†ìŠµë‹ˆë‹¤"
            
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            # ê¸°ì¡´ ë§¤ë¬¼ í™•ì¸
            cursor.execute("SELECT id, collected_at FROM properties WHERE naver_link = ?", (naver_link,))
            existing = cursor.fetchone()
            
            current_time_str = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            
            if existing:
                # ì—…ë°ì´íŠ¸
                existing_id, old_collected_at = existing
                property_data['collected_at'] = current_time_str
                
                # ë™ì  UPDATE ì¿¼ë¦¬ ìƒì„±
                columns = []
                values = []
                for key, value in property_data.items():
                    if key != 'id':  # idëŠ” ì—…ë°ì´íŠ¸í•˜ì§€ ì•ŠìŒ
                        columns.append(f"{key} = ?")
                        values.append(value)
                
                update_query = f"UPDATE properties SET {', '.join(columns)} WHERE id = ?"
                values.append(existing_id)
                
                cursor.execute(update_query, values)
                conn.commit()
                conn.close()
                
                return f"ğŸ”„ ì—…ë°ì´íŠ¸: {naver_link.split('/')[-1]} (ì´ì „: {old_collected_at})"
            else:
                # ì‹ ê·œ ì‚½ì…
                property_data['collected_at'] = current_time_str
                property_data['created_at'] = current_time_str
                
                columns = ', '.join(property_data.keys())
                placeholders = ', '.join(['?' for _ in property_data.keys()])
                insert_query = f"INSERT INTO properties ({columns}) VALUES ({placeholders})"
                
                cursor.execute(insert_query, list(property_data.values()))
                conn.commit()
                conn.close()
                
                return f"âœ… ì‹ ê·œ: {naver_link.split('/')[-1]}"
                
        except Exception as e:
            return f"âŒ ì˜¤ë¥˜: {e}"
    
    def import_csv_to_db_from_dataframe(self, df: pd.DataFrame, overwrite: bool = True) -> int:
        """ğŸ“¥ DataFrameì„ ì§ì ‘ DBë¡œ ì €ì¥ (CSV íŒŒì¼ ê±°ì¹˜ì§€ ì•ŠìŒ)"""
        try:
            print(f"ğŸ”„ DataFrame â†’ DB ì§ì ‘ ë³€í™˜: {len(df)}ê°œ ë ˆì½”ë“œ")
            
            # DB í˜•ì‹ìœ¼ë¡œ ë³€í™˜
            db_df = self.csv_to_db_dataframe(df)
            print(f"ğŸ”„ DB í˜•ì‹ ë³€í™˜ ì™„ë£Œ: {len(db_df)}ê°œ ë ˆì½”ë“œ")
            
            # ë®ì–´ì“°ê¸° ì˜µì…˜ ì²˜ë¦¬
            if overwrite:
                print("ğŸ—‘ï¸ ê¸°ì¡´ DB ë°ì´í„° ì‚­ì œ ì¤‘...")
                self.clear_all_properties()
            
            # DBì— ì €ì¥
            saved_count = 0
            conn = sqlite3.connect(self.db_path)
            
            for _, row in db_df.iterrows():
                try:
                    # INSERT ì¿¼ë¦¬ ì‹¤í–‰
                    columns = ', '.join(row.index)
                    placeholders = ', '.join(['?' for _ in row.index])
                    query = f"INSERT INTO properties ({columns}) VALUES ({placeholders})"
                    
                    conn.execute(query, tuple(row.values))
                    saved_count += 1
                    
                except Exception as e:
                    print(f"âš ï¸ ë ˆì½”ë“œ ì €ì¥ ì˜¤ë¥˜: {e}")
                    continue
            
            conn.commit()
            conn.close()
            
            print(f"âœ… DataFrame â†’ DB ì €ì¥ ì™„ë£Œ: {saved_count}/{len(db_df)}ê°œ ì €ì¥ë¨")
            return saved_count
            
        except Exception as e:
            print(f"âŒ DataFrame â†’ DB ì €ì¥ ì‹¤íŒ¨: {e}")
            return 0
    
    def import_with_upsert(self, df: pd.DataFrame) -> dict:
        """ğŸ“¥ UPSERT ë°©ì‹ìœ¼ë¡œ DataFrame ë°ì´í„° ì €ì¥ (ì¤‘ë³µ ì‹œ ì—…ë°ì´íŠ¸)"""
        try:
            print(f"ğŸ”„ UPSERT ë°©ì‹ DB ì €ì¥: {len(df)}ê°œ ë ˆì½”ë“œ")
            
            # DB í˜•ì‹ìœ¼ë¡œ ë³€í™˜
            db_df = self.csv_to_db_dataframe(df)
            
            # í†µê³„ ë³€ìˆ˜
            stats = {
                'new_count': 0,
                'updated_count': 0,
                'error_count': 0,
                'details': []
            }
            
            # ê° ë ˆì½”ë“œì— ëŒ€í•´ UPSERT ì‹¤í–‰
            for _, row in db_df.iterrows():
                row_dict = row.to_dict()
                result = self.upsert_property(row_dict)
                stats['details'].append(result)
                
                if "âœ… ì‹ ê·œ" in result:
                    stats['new_count'] += 1
                elif "ğŸ”„ ì—…ë°ì´íŠ¸" in result:
                    stats['updated_count'] += 1
                else:
                    stats['error_count'] += 1
            
            if stats['error_count'] > 0:
                print(f"âœ… UPSERT ì™„ë£Œ: ì‹ ê·œ {stats['new_count']}ê°œ, ì—…ë°ì´íŠ¸ {stats['updated_count']}ê°œ, âš ï¸ ì˜¤ë¥˜ {stats['error_count']}ê°œ")
            else:
                print(f"âœ… UPSERT ì™„ë£Œ: ì‹ ê·œ {stats['new_count']}ê°œ, ì—…ë°ì´íŠ¸ {stats['updated_count']}ê°œ")
            
            return stats
            
        except Exception as e:
            print(f"âŒ UPSERT ì‹¤íŒ¨: {e}")
            return {'new_count': 0, 'updated_count': 0, 'error_count': len(df), 'details': []}
        
    def apply_filters(self, df):
        """í•„ìˆ˜ ì¡°ê±´ í•„í„°ë§ ì ìš©"""
        filtered_df = df.copy()
        
        # ë³´ì¦ê¸ˆ í•„í„°
        if 'deposit' in filtered_df.columns:
            filtered_df = filtered_df[filtered_df['deposit'] <= self.filter_conditions['max_deposit']]
        
        # ì›”ì„¸ í•„í„°
        if 'monthly_rent' in filtered_df.columns:
            filtered_df = filtered_df[filtered_df['monthly_rent'] <= self.filter_conditions['max_monthly_rent']]
        
        # ê´€ë¦¬ë¹„ í¬í•¨ ì›”ì„¸ í•„í„°
        if 'monthly_rent' in filtered_df.columns and 'management_fee' in filtered_df.columns:
            total_rent = filtered_df['monthly_rent'] + filtered_df['management_fee'].fillna(0)
            filtered_df = filtered_df[total_rent <= self.filter_conditions['max_total_monthly']]
        
        # ì¸µìˆ˜ í•„í„° (None ê°’ ì•ˆì „ ì²˜ë¦¬)
        if 'floor' in filtered_df.columns:
            # None ê°’ ì œì™¸í•˜ê³  ìˆ«ì íƒ€ì…ë§Œ í•„í„°ë§
            floor_valid = filtered_df['floor'].notna() & filtered_df['floor'].apply(lambda x: isinstance(x, (int, float)))
            if floor_valid.any():
                filtered_df = filtered_df[
                    floor_valid &
                    (filtered_df['floor'] >= self.filter_conditions['min_floor']) &
                    (filtered_df['floor'] <= self.filter_conditions['max_floor'])
                ]
        
        # ë©´ì  í•„í„°
        if 'area_sqm' in filtered_df.columns:
            # 20í‰ = 66ã¡ë¡œ ë³€í™˜
            area_pyeong = filtered_df['area_sqm'] / 3.306
            filtered_df = filtered_df[area_pyeong >= self.filter_conditions['min_area_pyeong']]
        
        # ê´€ë¦¬ë¹„ í•„í„°
        if 'management_fee' in filtered_df.columns:
            filtered_df = filtered_df[
                filtered_df['management_fee'].fillna(0) <= self.filter_conditions['max_management_fee']
            ]
        
        return filtered_df
    
    def calculate_scores(self, df):
        """ì„ íƒ ì¡°ê±´ ì ìˆ˜ ê³„ì‚°"""
        df = df.copy()
        df['score'] = 0
        
        # ì¸µê³  ì ìˆ˜
        if 'ceiling_height' in df.columns:
            ceiling_condition = df['ceiling_height'] >= 2.8
            df.loc[ceiling_condition, 'score'] += 1
        
        # ì—­ì„¸ê¶Œ ì ìˆ˜
        if 'near_station' in df.columns:
            station_condition = df['near_station'] == True
            df.loc[station_condition, 'score'] += 2
        
        # ì£¼ì°¨ ì ìˆ˜ (ê°€ì¥ ì¤‘ìš”)
        if 'parking_available' in df.columns:
            parking_condition = df['parking_available'] == True
            df.loc[parking_condition, 'score'] += 3
        
        return df
    
    def create_labels(self, df):
        """ì„ íƒ ì¡°ê±´ ë¼ë²¨ ìƒì„±"""
        df = df.copy()
        labels = []
        
        for idx, row in df.iterrows():
            row_labels = []
            
            # ì¸µê³  ë¼ë²¨
            if 'ceiling_height' in row and pd.notna(row['ceiling_height']):
                if row['ceiling_height'] >= 2.8:
                    row_labels.append(f"ì¸µê³  {row['ceiling_height']:.1f}m â­")
            
            # ì—­ì„¸ê¶Œ ë¼ë²¨
            if 'near_station' in row and row['near_station']:
                row_labels.append("ì—­ì„¸ê¶Œ ğŸš‡")
            
            # ì£¼ì°¨ ë¼ë²¨
            if 'parking_available' in row and row['parking_available']:
                row_labels.append("ì£¼ì°¨ê°€ëŠ¥ ğŸš—")
            
            labels.append(" | ".join(row_labels) if row_labels else "")
        
        df['labels'] = labels
        return df
    
    def process_data(self, public_df=None, naver_df=None):
        """ì „ì²´ ë°ì´í„° ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸"""
        print("ë°ì´í„° ì²˜ë¦¬ ì‹œì‘...")
        
        # ë°ì´í„° ë³‘í•©
        if public_df is not None and naver_df is not None:
            # í•˜ì´ë¸Œë¦¬ë“œ: ê³µê³µë°ì´í„° + ë„¤ì´ë²„ ë¶€ë™ì‚°
            merged_df = self.merge_data_sources(public_df, naver_df)
        elif public_df is not None:
            merged_df = public_df.copy()
        elif naver_df is not None:
            merged_df = naver_df.copy()
        else:
            # ìƒ˜í”Œ ë°ì´í„° ìƒì„±
            merged_df = self.generate_sample_data()
        
        print(f"ë³‘í•©ëœ ë°ì´í„°: {len(merged_df)}ê±´")
        
        # í•„ìˆ˜ ì¡°ê±´ í•„í„°ë§
        filtered_df = self.apply_filters(merged_df)
        print(f"í•„í„°ë§ í›„: {len(filtered_df)}ê±´")
        
        # ì ìˆ˜ ê³„ì‚°
        scored_df = self.calculate_scores(filtered_df)
        
        # ë¼ë²¨ ìƒì„±
        labeled_df = self.create_labels(scored_df)
        
        # ì´ ì›”ì„¸ ê³„ì‚° (ì›”ì„¸ + ê´€ë¦¬ë¹„)
        if 'monthly_rent' in labeled_df.columns and 'management_fee' in labeled_df.columns:
            labeled_df['total_monthly_cost'] = (
                labeled_df['monthly_rent'] + labeled_df['management_fee'].fillna(0)
            )
        
        print("ë°ì´í„° ì²˜ë¦¬ ì™„ë£Œ")
        return labeled_df
    
    def merge_data_sources(self, public_df, naver_df):
        """ê³µê³µë°ì´í„°ì™€ ë„¤ì´ë²„ ë¶€ë™ì‚° ë°ì´í„° ë³‘í•©"""
        # ê°„ë‹¨í•œ ë³‘í•© ë¡œì§ (ì‹¤ì œë¡œëŠ” ì£¼ì†Œ/ê±´ë¬¼ëª… ë§¤ì¹­ í•„ìš”)
        merged_list = []
        
        # ê³µê³µë°ì´í„° ìš°ì„  ì‚¬ìš©
        for idx, row in public_df.iterrows():
            merged_row = row.to_dict()
            
            # ë„¤ì´ë²„ ë°ì´í„°ì—ì„œ ë§¤ì¹­ë˜ëŠ” í•­ëª© ì°¾ê¸° (ê°„ë‹¨í•œ ì˜ˆì‹œ)
            matching_naver = naver_df[
                naver_df['region'] == row.get('region', '')
            ].iloc[0:1] if len(naver_df) > 0 else pd.DataFrame()
            
            if not matching_naver.empty:
                naver_row = matching_naver.iloc[0]
                # ë„¤ì´ë²„ì—ë§Œ ìˆëŠ” ì •ë³´ ì¶”ê°€
                for col in ['ceiling_height', 'parking_available', 'near_station', 'naver_link']:
                    if col in naver_row:
                        merged_row[col] = naver_row[col]
                merged_row['data_source'] = 'ê³µê³µ+ë„¤ì´ë²„'
            
            merged_list.append(merged_row)
        
        # ë„¤ì´ë²„ ì „ìš© ë°ì´í„° ì¶”ê°€
        for idx, row in naver_df.iterrows():
            if row.get('region', '') not in public_df.get('region', pd.Series()).values:
                merged_list.append(row.to_dict())
        
        return pd.DataFrame(merged_list)
    
    def generate_sample_data(self, num_samples=100):
        """ìƒ˜í”Œ ë°ì´í„° ìƒì„±"""
        import random
        
        regions = ['ê°•ë‚¨êµ¬', 'ì„œì´ˆêµ¬', 'ì†¡íŒŒêµ¬', 'ë§ˆí¬êµ¬', 'ìš©ì‚°êµ¬']
        districts = ['ì—­ì‚¼ë™', 'ë°˜í¬ë™', 'ì ì‹¤ë™', 'ìƒì•”ë™', 'í•œë‚¨ë™'] * 20
        
        sample_data = []
        for i in range(num_samples):
            region = random.choice(regions)
            data = {
                'region': region,
                'district': random.choice(districts),
                'building_name': f'{region} í…ŒìŠ¤íŠ¸ì•„íŒŒíŠ¸ {i+1}ë™',
                'full_address': f'{region} {random.choice(districts)} {i+1}ë²ˆì§€',
                'area_sqm': random.randint(60, 120),
                'area_pyeong': random.randint(60, 120) / 3.3058,
                'floor': random.randint(-1, 2),
                'deposit': random.randint(1000, 2500),
                'monthly_rent': random.randint(80, 180),
                'management_fee': random.randint(15, 35),
                'ceiling_height': round(random.uniform(2.6, 3.0), 1),
                'parking_available': random.choice([True, False]),
                'near_station': random.choice([True, False]),
                'build_year': random.randint(2000, 2023),
                'naver_link': f'https://new.land.naver.com/detail/test_{i}',
                'data_source': 'ìƒ˜í”Œë°ì´í„°',
                'collected_at': datetime.now()
            }
            sample_data.append(data)
        
        return pd.DataFrame(sample_data)
    
    def save_to_database(self, df):
        """ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥"""
        # ê¸°ì¡´ ë°ì´í„°ë² ì´ìŠ¤ íŒŒì¼ ì‚­ì œ (ìŠ¤í‚¤ë§ˆ ì—…ë°ì´íŠ¸ë¥¼ ìœ„í•´)
        if os.path.exists(self.db_path):
            os.remove(self.db_path)
            print("ê¸°ì¡´ ë°ì´í„°ë² ì´ìŠ¤ ì‚­ì œë¨")
        
        self.create_tables()
        conn = sqlite3.connect(self.db_path)
        
        # ìƒˆ ë°ì´í„° ì €ì¥
        df.to_sql('properties', conn, if_exists='append', index=False)
        
        conn.commit()
        conn.close()
        print(f"ë°ì´í„°ë² ì´ìŠ¤ì— {len(df)}ê±´ ì €ì¥ ì™„ë£Œ")
    
    def load_from_database(self):
        """ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ë¡œë“œ"""
        if not os.path.exists(self.db_path):
            return pd.DataFrame()
            
        conn = sqlite3.connect(self.db_path)
        df = pd.read_sql_query("SELECT * FROM properties ORDER BY score DESC, deposit ASC", conn)
        conn.close()
        return df

# ì‚¬ìš© ì˜ˆì‹œ
    def apply_range_filters(self, df, filter_conditions):
        """ë²”ìœ„ í•„í„° ì ìš© í•¨ìˆ˜"""
        if df.empty or not filter_conditions:
            return df
            
        filtered_df = df.copy()
        
        # ì§€ì—­ í•„í„°
        if 'districts' in filter_conditions and filter_conditions['districts']:
            if 'district' in filtered_df.columns:
                filtered_df = filtered_df[filtered_df['district'].isin(filter_conditions['districts'])]
            elif 'region' in filtered_df.columns:
                filtered_df = filtered_df[filtered_df['region'].isin(filter_conditions['districts'])]
        
        # ë³´ì¦ê¸ˆ ë²”ìœ„ í•„í„°
        if 'deposit_range' in filter_conditions and 'deposit' in filtered_df.columns:
            min_deposit, max_deposit = filter_conditions['deposit_range']
            filtered_df = filtered_df[
                (filtered_df['deposit'] >= min_deposit) &
                (filtered_df['deposit'] <= max_deposit)
            ]
        
        # ì›”ì„¸ ë²”ìœ„ í•„í„°
        if 'rent_range' in filter_conditions and 'monthly_rent' in filtered_df.columns:
            min_rent, max_rent = filter_conditions['rent_range']
            filtered_df = filtered_df[
                (filtered_df['monthly_rent'] >= min_rent) &
                (filtered_df['monthly_rent'] <= max_rent)
            ]
        
        # ë©´ì  ë²”ìœ„ í•„í„°
        if 'area_range' in filter_conditions and 'area_pyeong' in filtered_df.columns:
            min_area, max_area = filter_conditions['area_range']
            filtered_df = filtered_df[
                (filtered_df['area_pyeong'] >= min_area) &
                (filtered_df['area_pyeong'] <= max_area)
            ]
        
        return filtered_df
    
    def apply_sorting(self, df, sort_option):
        """ì •ë ¬ ì ìš© í•¨ìˆ˜"""
        if df.empty or not sort_option:
            return df
            
        sort_mapping = {
            "ë³´ì¦ê¸ˆ ë‚®ì€ìˆœ": ('deposit', True),
            "ë³´ì¦ê¸ˆ ë†’ì€ìˆœ": ('deposit', False),
            "ì›”ì„¸ ë‚®ì€ìˆœ": ('monthly_rent', True),
            "ì›”ì„¸ ë†’ì€ìˆœ": ('monthly_rent', False),
            "ë©´ì  í°ìˆœ": ('area_pyeong', False),
            "ë©´ì  ì‘ì€ìˆœ": ('area_pyeong', True),
            "ì ìˆ˜ ë†’ì€ìˆœ": ('score', False),
            "ë“±ë¡ìˆœ": (None, None)
        }
        
        column, ascending = sort_mapping.get(sort_option, (None, None))
        if column and column in df.columns:
            return df.sort_values(column, ascending=ascending)
        
        return df

if __name__ == "__main__":
    processor = PropertyDataProcessor()
    
    # ìƒ˜í”Œ ë°ì´í„°ë¡œ í…ŒìŠ¤íŠ¸
    sample_data = processor.generate_sample_data(50)
    processed_data = processor.process_data(public_df=sample_data)
    
    print("\nì²˜ë¦¬ëœ ë°ì´í„° ìƒ˜í”Œ:")
    print(processed_data[['region', 'deposit', 'monthly_rent', 'score', 'labels']].head(10))
    
    # ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥
    processor.save_to_database(processed_data)
    
    # ë¡œë“œ í…ŒìŠ¤íŠ¸
    loaded_data = processor.load_from_database()
    print(f"\në¡œë“œëœ ë°ì´í„°: {len(loaded_data)}ê±´")
