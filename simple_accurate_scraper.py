#!/usr/bin/env python3
"""
ğŸ¯ ê°„ë‹¨í•˜ê³  ì •í™•í•œ ì§€ì—­ë³„ ìˆ˜ì§‘ê¸°
- ì§ì ‘ ê°•ë‚¨êµ¬ ì¤‘ì‹¬ìœ¼ë¡œ ì´ë™
- ë„¤ì´ë²„ ì§€ë„ì—ì„œ ì‹¤ì œ ì‚¬ìš©í•˜ëŠ” API íŒŒë¼ë¯¸í„° ëª¨ë‹ˆí„°ë§
- ë¸Œë¼ìš°ì €ì™€ 100% ë™ì¼í•œ ê²°ê³¼ ë³´ì¥
"""

import asyncio
import json
import re
import requests
from datetime import datetime
from playwright.async_api import async_playwright

class SimpleAccurateScraper:
    def __init__(self):
        self.api_base_url = 'https://m.land.naver.com/cluster/ajax/articleList'
        
        # ê°•ë‚¨êµ¬ ì¤‘ì‹¬ ì¢Œí‘œë¡œ ì§ì ‘ ì´ë™
        self.gangnam_url = "https://m.land.naver.com/map/37.517:127.047:13/SG:SMS/B2?wprcMax=2000&rprcMax=130&spcMin=66&flrMin=-1&flrMax=2"
        
        self.browser_config = {
            'headless': False,
            'args': ['--disable-blink-features=AutomationControlled']
        }
    
    async def capture_real_api_requests(self):
        """ğŸ¯ ë¸Œë¼ìš°ì €ì—ì„œ ì‹¤ì œ API ìš”ì²­ ìº¡ì²˜"""
        print("ğŸ¯ ê°•ë‚¨êµ¬ ì‹¤ì œ API ìš”ì²­ ìº¡ì²˜ ì¤‘...")
        
        captured_requests = []
        
        async with async_playwright() as p:
            browser = await p.chromium.launch(**self.browser_config)
            page = await browser.new_page()
            
            # ë„¤íŠ¸ì›Œí¬ ìš”ì²­ ëª¨ë‹ˆí„°ë§
            def handle_request(request):
                if 'articleList' in request.url:
                    print(f"   ğŸ“¡ API ìš”ì²­ ìº¡ì²˜: {request.url}")
                    captured_requests.append({
                        'url': request.url,
                        'params': dict(request.url.split('?')[1].split('&') if '?' in request.url else [])
                    })
            
            page.on('request', handle_request)
            
            try:
                # ê°•ë‚¨êµ¬ ì¤‘ì‹¬ìœ¼ë¡œ ì´ë™
                print("   ğŸ“ ê°•ë‚¨êµ¬ ì§€ë„ í˜ì´ì§€ ì ‘ì†...")
                await page.goto(self.gangnam_url, wait_until='networkidle')
                await asyncio.sleep(5)
                
                # ì§€ë„ ì¡°ì‘í•˜ì—¬ API í˜¸ì¶œ ìœ ë„
                print("   ğŸ”„ ì§€ë„ ìƒí˜¸ì‘ìš©...")
                await page.evaluate("window.scrollTo(0, 100)")
                await asyncio.sleep(2)
                
                # ì¤Œ ë ˆë²¨ ì¡°ì •
                for _ in range(2):
                    try:
                        zoom_in = page.locator('button[data-action="zoom-in"], .zoom_in, [title*="í™•ëŒ€"]')
                        if await zoom_in.count() > 0:
                            await zoom_in.first.click()
                            await asyncio.sleep(1)
                    except:
                        pass
                
                # ìµœì¢… URLê³¼ ìƒíƒœ í™•ì¸
                final_url = page.url
                print(f"   ğŸ“ ìµœì¢… URL: {final_url}")
                
                # URLì—ì„œ íŒŒë¼ë¯¸í„° ì¶”ì¶œ
                api_params = self.extract_params_from_url(final_url)
                
                # ì´ ë§¤ë¬¼ ìˆ˜ í™•ì¸
                await asyncio.sleep(3)
                try:
                    page_text = await page.content()
                    total_match = re.search(r'ì´\s*(\d{1,4})\+?\s*ê°œì˜?\s*ë§¤ë¬¼', page_text)
                    if total_match:
                        total_count = total_match.group(1)
                        api_params['totCnt'] = total_count
                        print(f"   ğŸ“Š ì´ ë§¤ë¬¼ ìˆ˜: {total_count}ê°œ")
                except:
                    print("   âš ï¸ ì´ ë§¤ë¬¼ ìˆ˜ ì¶”ì¶œ ì‹¤íŒ¨")
                
                return api_params
                
            except Exception as e:
                print(f"   âŒ API ìº¡ì²˜ ì‹¤íŒ¨: {e}")
                return None
                
            finally:
                await browser.close()
    
    def extract_params_from_url(self, url: str) -> dict:
        """URLì—ì„œ API íŒŒë¼ë¯¸í„° ì¶”ì¶œ"""
        params = {}
        
        # ì¢Œí‘œ ì¶”ì¶œ
        coord_match = re.search(r'/map/([0-9.]+):([0-9.]+):(\d+)', url)
        if coord_match:
            lat, lon, zoom = coord_match.groups()
            params.update({
                'lat': lat,
                'lon': lon,
                'z': zoom
            })
            
            # ì¢Œí‘œ ê¸°ë°˜ ê²½ê³„ ê³„ì‚° (ê°•ë‚¨êµ¬ì— ë§ê²Œ ì¢í˜)
            lat_f = float(lat)
            lon_f = float(lon)
            
            # ê°•ë‚¨êµ¬ì— ìµœì í™”ëœ ë²”ìœ„
            lat_range = 0.025  # ê¸°ì¡´ë³´ë‹¤ ì¢í˜
            lon_range = 0.035  # ê¸°ì¡´ë³´ë‹¤ ì¢í˜
            
            params.update({
                'btm': str(lat_f - lat_range),
                'lft': str(lon_f - lon_range), 
                'top': str(lat_f + lat_range),
                'rgt': str(lon_f + lon_range)
            })
            
            print(f"   âœ… ì¢Œí‘œ: lat={lat}, lon={lon}")
            print(f"   ğŸ“ ë²”ìœ„: {params['btm']} ~ {params['top']} (ë‚¨ë¶)")
            print(f"           {params['lft']} ~ {params['rgt']} (ë™ì„œ)")
        
        # URL í•„í„° íŒŒë¼ë¯¸í„° ì¶”ì¶œ
        url_filters = ['wprcMax', 'rprcMax', 'spcMin', 'flrMin', 'flrMax']
        for param in url_filters:
            match = re.search(f'{param}=([^&]+)', url)
            if match:
                params[param] = match.group(1)
                print(f"   âœ… í•„í„°: {param}={match.group(1)}")
        
        # ê¸°ë³¸ API íŒŒë¼ë¯¸í„°
        params.update({
            'rletTpCd': 'SG:SMS',
            'tradTpCd': 'B2',
            'showR0': '',
            'cortarNo': ''
        })
        
        return params
    
    def test_api_collection(self, api_params: dict, max_pages: int = 3):
        """ğŸ§ª ì¶”ì¶œëœ íŒŒë¼ë¯¸í„°ë¡œ API í…ŒìŠ¤íŠ¸"""
        print(f"ğŸ§ª API ìˆ˜ì§‘ í…ŒìŠ¤íŠ¸ (ìµœëŒ€ {max_pages}í˜ì´ì§€)...")
        
        headers = {
            'User-Agent': 'Mozilla/5.0 (iPhone; CPU iPhone OS 17_0 like Mac OS X) AppleWebKit/605.1.15',
            'Accept': 'application/json',
            'Referer': 'https://m.land.naver.com/'
        }
        
        all_properties = []
        
        for page_num in range(1, max_pages + 1):
            print(f"   ğŸ“„ {page_num}í˜ì´ì§€...")
            
            current_params = api_params.copy()
            current_params['page'] = str(page_num)
            
            try:
                response = requests.get(self.api_base_url, params=current_params, headers=headers, timeout=30)
                
                if response.status_code == 200:
                    data = response.json()
                    
                    if 'body' in data and isinstance(data['body'], list):
                        page_properties = data['body']
                        print(f"      âœ… {len(page_properties)}ê°œ ë§¤ë¬¼")
                        
                        # ì¢Œí‘œ ê²€ì¦
                        valid_count = 0
                        for prop in page_properties:
                            lat = prop.get('lat', 0)
                            lng = prop.get('lng', 0)
                            
                            # ê°•ë‚¨êµ¬ ë²”ìœ„ ê²€ì¦ (ì—„ê²©)
                            if 37.45 <= lat <= 37.55 and 127.0 <= lng <= 127.15:
                                valid_count += 1
                                
                                # ê°„ë‹¨í•œ ë§¤ë¬¼ ì •ë³´
                                all_properties.append({
                                    'id': prop.get('atclNo', ''),
                                    'name': prop.get('atclNm', ''),
                                    'deposit': prop.get('prc', 0),
                                    'rent': prop.get('rentPrc', 0),
                                    'area': prop.get('spc2', 0),
                                    'lat': lat,
                                    'lng': lng,
                                    'link': f"https://m.land.naver.com/article/info/{prop.get('atclNo', '')}"
                                })
                        
                        print(f"      ğŸ¯ ê°•ë‚¨êµ¬ ë²”ìœ„ ë‚´: {valid_count}ê°œ")
                        
                        if len(page_properties) == 0:
                            break
                            
                    else:
                        print(f"      âŒ ì‘ë‹µ í˜•ì‹ ì˜¤ë¥˜")
                        break
                else:
                    print(f"      âŒ ìš”ì²­ ì‹¤íŒ¨: {response.status_code}")
                    break
                    
            except Exception as e:
                print(f"      âŒ ì˜¤ë¥˜: {e}")
                break
        
        print(f"ğŸ‰ ìˆ˜ì§‘ ì™„ë£Œ: ì´ {len(all_properties)}ê°œ ê°•ë‚¨êµ¬ ë§¤ë¬¼")
        return all_properties

# í…ŒìŠ¤íŠ¸ ì‹¤í–‰
async def main():
    scraper = SimpleAccurateScraper()
    
    # 1ë‹¨ê³„: ì‹¤ì œ API íŒŒë¼ë¯¸í„° ì¶”ì¶œ
    api_params = await scraper.capture_real_api_requests()
    
    if api_params:
        print(f"\nğŸ¯ ì¶”ì¶œëœ API íŒŒë¼ë¯¸í„°:")
        for key, value in api_params.items():
            print(f"   {key}: {value}")
        
        # 2ë‹¨ê³„: API í…ŒìŠ¤íŠ¸
        properties = scraper.test_api_collection(api_params, max_pages=3)
        
        if properties:
            print(f"\nğŸ“‹ ìˆ˜ì§‘ëœ ê°•ë‚¨êµ¬ ë§¤ë¬¼ ìƒ˜í”Œ:")
            for i, prop in enumerate(properties[:5]):
                print(f"   {i+1}. {prop['name']} | {prop['deposit']}ë§Œì›/{prop['rent']}ë§Œì› | {prop['area']}ã¡")
                print(f"      ì¢Œí‘œ: ({prop['lat']:.4f}, {prop['lng']:.4f}) | {prop['link']}")
    else:
        print("\nâŒ API íŒŒë¼ë¯¸í„° ì¶”ì¶œ ì‹¤íŒ¨")

if __name__ == "__main__":
    asyncio.run(main())
